---
title: Jan
description: Build, run, and own your AI. From laptop to superintelligence.
keywords:
  [
    Jan,
    Jan AI,
    open superintelligence,
    AI ecosystem,
    local AI,
    private AI,
    self-hosted AI,
    llama.cpp,
    Model Context Protocol,
    MCP,
    GGUF models,
    large language model,
    LLM,
  ]
---

import { Callout } from 'nextra/components'
import FAQBox from '@/components/FaqBox'

# Jan

![Jan's Cover Image](./_assets/jan-app-new.png)

## Jan's Goal

> Jan's goal is to build superintelligence that you can self-host and use locally.

## What is Jan?

Jan is an open-source AI ecosystem that runs on your hardware. We're building towards open superintelligence - a complete AI platform you actually own.

### The Ecosystem

**Models**: We build specialized models for real tasks, not general-purpose assistants:
- **Jan-Nano (32k/128k)**: 4B parameters designed for deep research with MCP. The 128k version processes entire papers, codebases, or legal documents in one go
- **Lucy**: 1.7B model that runs agentic web search on your phone. Small enough for CPU, smart enough for complex searches
- **Jan-v1**: 4B model for agentic reasoning and tool use, achieving 91.1% on SimpleQA

We also integrate the best open-source models - from OpenAI's gpt-oss to community GGUF models on Hugging Face. The goal: make powerful AI accessible to everyone, not just those with server farms.

**Applications**: Jan Desktop runs on your computer today. Web, mobile, and server versions coming in late 2025. Everything syncs, everything works together.

**Tools**: Connect to the real world through [Model Context Protocol (MCP)](./mcp). Design with Canva, analyze data in Jupyter notebooks, control browsers, execute code in E2B sandboxes. Your AI can actually do things, not just talk about them.

<Callout>
API keys are optional. No account needed. Just download and run. Bring your own API keys to connect your favorite cloud models.
</Callout>

### Core Features

- **Run Models Locally**: Download any GGUF model from Hugging Face, use OpenAI's gpt-oss models, or connect to cloud providers
- **OpenAI-Compatible API**: Local server at `localhost:1337` works with tools like [Continue](./server-examples/continue-dev) and [Cline](https://cline.bot/)
- **Extend with MCP Tools**: Browser automation, web search, data analysis, design tools - all through natural language
- **Your Choice of Infrastructure**: Run on your laptop, self-host on your servers (soon), or use cloud when you need it

### Growing MCP Integrations

Jan connects to real tools through MCP:
- **Creative Work**: Generate designs with Canva
- **Data Analysis**: Execute Python in Jupyter notebooks
- **Web Automation**: Control browsers with Browserbase and Browser Use
- **Code Execution**: Run code safely in E2B sandboxes
- **Search & Research**: Access current information via Exa, Perplexity, and Octagon
- **More coming**: The MCP ecosystem is expanding rapidly

## Philosophy

Jan is built to be user-owned:
- **Open Source**: Apache 2.0 license - truly free
- **Local First**: Your data stays on your device. Internet is optional
- **Privacy Focused**: We don't collect or sell user data. See our [Privacy Policy](./privacy)
- **No Lock-in**: Export your data anytime. Use any model. Switch between local and cloud

<Callout type="info">
We're building AI that respects your choices. Not another wrapper around someone else's API.
</Callout>

## Quick Start

1. [Download Jan](./quickstart) for your operating system
2. Choose a model - download locally or add cloud API keys
3. Start chatting or connect tools via MCP
4. Build with our [API](https://jan.ai/api-reference)

## Acknowledgements

Jan is built on the shoulders of giants:
- [Llama.cpp](https://github.com/ggerganov/llama.cpp) for inference
- [Model Context Protocol](https://modelcontextprotocol.io) for tool integration
- The open-source community that makes this possible

## FAQs

<FAQBox title="What is Jan?">
  Jan is an open-source AI ecosystem building towards superintelligence you can self-host. Today it's a desktop app that runs AI models locally. Tomorrow it's a complete platform across all your devices.
</FAQBox>

<FAQBox title="How is this different from other AI platforms?">
  Other platforms are models behind APIs you rent. Jan is a complete AI ecosystem you own. Run any model, use real tools through MCP, keep your data private, and never pay subscriptions for local use.
</FAQBox>

<FAQBox title="What models can I use?">
  **Jan Models:**
  - Jan-Nano (32k/128k) - Deep research with MCP integration
  - Lucy - Mobile-optimized agentic search (1.7B)
  - Jan-v1 - Agentic reasoning and tool use (4B)
  
  **Open Source:**
  - OpenAI's gpt-oss models (120b and 20b)
  - Any GGUF model from Hugging Face
  
  **Cloud (with your API keys):**
  - OpenAI, Anthropic, Mistral, Groq, and more
</FAQBox>

<FAQBox title="What are MCP tools?">
  MCP (Model Context Protocol) lets AI interact with real applications. Instead of just generating text, your AI can create designs in Canva, analyze data in Jupyter, browse the web, and execute code - all through conversation.
</FAQBox>

<FAQBox title="Is Jan compatible with my system?">
  **Supported OS**:
  - [Windows 10+](/docs/desktop/windows#compatibility)
  - [macOS 12+](/docs/desktop/mac#compatibility)
  - [Linux (Ubuntu 20.04+)](/docs/desktop/linux)

  **Hardware**:
  - Minimum: 8GB RAM, 10GB storage
  - Recommended: 16GB RAM, GPU (NVIDIA/AMD/Intel), 50GB storage
  - Works with: NVIDIA (CUDA), AMD (Vulkan), Intel Arc, Apple Silicon
</FAQBox>

<FAQBox title="Is Jan really free?">
  **Local use**: Always free, no catches
  **Cloud models**: You pay providers directly (we add no markup)
  **Jan cloud**: Optional paid services coming 2025
  
  The core platform will always be free and open source.
</FAQBox>

<FAQBox title="How does Jan protect privacy?">
  - Runs 100% offline once models are downloaded
  - All data stored locally in [Jan Data Folder](/docs/data-folder)
  - No telemetry without explicit consent
  - Open source code you can audit

  <Callout type="warning">
    When using cloud providers through Jan, their privacy policies apply.
  </Callout>
</FAQBox>

<FAQBox title="Can I self-host Jan?">
  Yes. Download directly or build from [source](https://github.com/menloresearch/jan). Jan Server for production deployments coming late 2025.
</FAQBox>

<FAQBox title="When will mobile/web versions launch?">
  - **Jan Web**: Beta late 2025
  - **Jan Mobile**: Late 2025
  - **Jan Server**: Late 2025
  
  All versions will sync seamlessly.
</FAQBox>

<FAQBox title="How can I contribute?">
  - Code: [GitHub](https://github.com/menloresearch/jan)
  - Community: [Discord](https://discord.gg/FTk2MvZwJH)
  - Testing: Help evaluate models and report bugs
  - Documentation: Improve guides and tutorials
</FAQBox>

<FAQBox title="Are you hiring?">
  Yes! We love hiring from our community. Check [Careers](https://menlo.bamboohr.com/careers).
</FAQBox>