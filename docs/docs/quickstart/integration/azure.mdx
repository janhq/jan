---
sidebar_position: 3
---

import azure from './assets/azure.png';

# Azure OpenAI

## Overview

This guide will show you how to integrate Azure OpenAI Service with Jan. The [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview?source=docs) offers robust APIs, making it simple for you to incorporate OpenAI's language models into your applications.

## How to Integrate Azure OpenAI with Jan

### Step 1: Configure Azure OpenAI Service API Key

1. Set yp and deploy the Azure OpenAI Service.
2. Once you've set up and deployed Azure OpenAI Service, you can find the endpoint and API key in [Azure OpenAI Studio](https://oai.azure.com/) under `Chat` > `View code`.

3. Set up the endpoint and API key for Azure OpenAI Service in the `~/jan/engines/openai.json` file.

```json title="~/jan/engines/openai.json"
{
  // https://hieujan.openai.azure.com/openai/deployments/gpt-35-hieu-jan/chat/completions?api-version=2023-07-01-preview
  "full_url": "https://<your-resource-name>.openai.azure.com/openai/deployments/<your-deployment-name>/chat/completions?api-version=<api-version>",
  "api_key": "<your-api-key>"
}
```

### Step 2: Model Configuration

1. Go to the `~/jan/models` directory. 
2. Make a new folder called `(your-deployment-name)`, like `gpt-35-hieu-jan`.
3. Create a `model.json` file inside the folder with the specified configurations:
  - Match the `id` property with both the folder name and your deployment name.
  - Set the `format` property as `api`.
  - Choose `openai` for the `engine` property.
  - Set the `state` property as `ready`.

```json title="~/jan/models/gpt-35-hieu-jan/model.json"
{
  "sources": [
    {
      "filename": "azure_openai",
      "url": "https://hieujan.openai.azure.com"
    }
  ],
  "id": "gpt-35-hieu-jan",
  "object": "model",
  "name": "Azure OpenAI GPT 3.5",
  "version": "1.0",
  "description": "Azure Open AI GPT 3.5 model is extremely good",
  "format": "api",
  "settings": {},
  "parameters": {},
  "metadata": {
    "author": "OpenAI",
    "tags": ["General", "Big Context Length"]
  },
  "engine": "openai"
}
```

#### Regarding `model.json`

- In `settings`, two crucial values are:
  - `ctx_len`: Defined based on the model's context size.
  - `prompt_template`: Defined based on the model's trained template (e.g., ChatML, Alpaca).
  - To set up the `prompt_template`:
    1. Visit Hugging Face.
    2. Locate the model (e.g., [Gemma 7b it](https://huggingface.co/google/gemma-7b-it)).
    3. Review the text and identify the template.
- In `parameters`, consider the following options. The fields in `parameters` are typically general and can be the same across models. An example is provided below:

```json
"parameters":{
  "temperature": 0.7,
  "top_p": 0.95,
  "stream": true,
  "max_tokens": 4096,
  "frequency_penalty": 0,
  "presence_penalty": 0
}
```

### Step 3: Start the Model

Restart Jan and go to the Hub. Find your model and click on the Use button.